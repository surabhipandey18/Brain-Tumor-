{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "provenance": [],
      "name": "Presence of Brain Tumor+XplainableAI with  GradCAM",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 377107,
          "datasetId": 165566,
          "databundleVersionId": 391742,
          "isSourceIdPinned": false
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 12745533,
          "datasetId": 672377,
          "databundleVersionId": 13364765,
          "isSourceIdPinned": false
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surabhipandey18/Brain-Tumor-/blob/main/Presence_of_Brain_Tumor%2BXplainableAI_with_GradCAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "navoneel_brain_mri_images_for_brain_tumor_detection_path = kagglehub.dataset_download('navoneel/brain-mri-images-for-brain-tumor-detection')\n",
        "sartajbhuvaji_brain_tumor_classification_mri_path = kagglehub.dataset_download('sartajbhuvaji/brain-tumor-classification-mri')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "B47xLpXBTQTq"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classifying MRI images for the presence of tumor/no-tumor and show the Grad-CAM for selected images**"
      ],
      "metadata": {
        "id": "QQA0om2fTQT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing dependency\n",
        "!pip install tf_keras_vis"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:22.531642Z",
          "iopub.execute_input": "2025-11-14T04:18:22.532283Z",
          "iopub.status.idle": "2025-11-14T04:18:25.685374Z",
          "shell.execute_reply.started": "2025-11-14T04:18:22.532257Z",
          "shell.execute_reply": "2025-11-14T04:18:25.684625Z"
        },
        "id": "6fNTNz8cTQT6"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#importing dependencies\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "import sklearn as sk\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os, shutil\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.utils.scores import CategoricalScore"
      ],
      "metadata": {
        "id": "Cb1QLzObdRuo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:25.686813Z",
          "iopub.execute_input": "2025-11-14T04:18:25.68708Z",
          "iopub.status.idle": "2025-11-14T04:18:25.692903Z",
          "shell.execute_reply.started": "2025-11-14T04:18:25.687053Z",
          "shell.execute_reply": "2025-11-14T04:18:25.692163Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"navoneel/brain-mri-images-for-brain-tumor-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "vAvoahbXc7LM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:25.693571Z",
          "iopub.execute_input": "2025-11-14T04:18:25.693797Z",
          "iopub.status.idle": "2025-11-14T04:18:25.815384Z",
          "shell.execute_reply.started": "2025-11-14T04:18:25.693781Z",
          "shell.execute_reply": "2025-11-14T04:18:25.814832Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#cropping brain images to removing skull and focus on brain\n",
        "def brain_crop(img):\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Otsu threshold for brain extraction\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Find brain region (largest connected component)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnt = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    x, y, w, h = cv2.boundingRect(cnt)\n",
        "    cropped = gray[y:y+h, x:x+w]\n",
        "\n",
        "    # Resize to model input size\n",
        "    cropped = cv2.resize(cropped, (224, 224))\n",
        "\n",
        "    # Convert grayscale → RGB so model still sees 3 channels\n",
        "    cropped = cv2.cvtColor(cropped, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    return cropped"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:25.815985Z",
          "iopub.execute_input": "2025-11-14T04:18:25.816157Z",
          "iopub.status.idle": "2025-11-14T04:18:25.821173Z",
          "shell.execute_reply.started": "2025-11-14T04:18:25.816143Z",
          "shell.execute_reply": "2025-11-14T04:18:25.820503Z"
        },
        "id": "GaIf_CWXTQUA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#installing file and classify it into tumor and non-tumor files\n",
        "file = \"/kaggle/input/brain-tumor-classification-mri/Training/\"\n",
        "binary = \"/kaggle/working/binary_dataset/\"\n",
        "\n",
        "os.makedirs(binary + \"tumor\", exist_ok=True)\n",
        "os.makedirs(binary + \"no_tumor\", exist_ok=True)\n",
        "\n",
        "# Process tumor images\n",
        "for cls in [\"glioma_tumor\", \"meningioma_tumor\", \"pituitary_tumor\"]:\n",
        "    class_path = os.path.join(file, cls)\n",
        "    for img_file in os.listdir(class_path):\n",
        "        img_path = os.path.join(class_path, img_file)\n",
        "        img = cv2.imread(img_path)\n",
        "\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        cropped = brain_crop(img)\n",
        "        cv2.imwrite(os.path.join(binary + \"tumor\", img_file), cropped)\n",
        "\n",
        "# Process no tumor images\n",
        "no_tumor_path = os.path.join(file, \"no_tumor\")\n",
        "for img_file in os.listdir(no_tumor_path):\n",
        "    img_path = os.path.join(no_tumor_path, img_file)\n",
        "    img = cv2.imread(img_path)\n",
        "\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    cropped = brain_crop(img)\n",
        "    cv2.imwrite(os.path.join(binary + \"no_tumor\", img_file), cropped)\n",
        "\n",
        "print(\"Skull-stripped binary dataset created at:\", binary)\n",
        "binary_path = '/kaggle/working/binary_dataset/'"
      ],
      "metadata": {
        "id": "DaTlaD2YdAOD",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:25.822779Z",
          "iopub.execute_input": "2025-11-14T04:18:25.823052Z",
          "iopub.status.idle": "2025-11-14T04:18:52.517727Z",
          "shell.execute_reply.started": "2025-11-14T04:18:25.823037Z",
          "shell.execute_reply": "2025-11-14T04:18:52.517081Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#printing 1 image out of each class\n",
        "plt.figure(figsize=(12, 12))\n",
        "classes = os.listdir(binary)\n",
        "for i in range(len(classes)):\n",
        "  class_path = os.path.join(binary_path, classes[i])\n",
        "  if os.path.isdir(class_path):\n",
        "    images_in_class = os.listdir(class_path)\n",
        "    if images_in_class:\n",
        "      plt.subplot(1, 4, i+1)\n",
        "      img_path = os.path.join(class_path, images_in_class[0])\n",
        "      plt.imshow(image.load_img(img_path))\n",
        "      plt.axis(\"off\")\n",
        "      plt.title(classes[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m4T9RVXBdJqB",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:52.518398Z",
          "iopub.execute_input": "2025-11-14T04:18:52.518574Z",
          "iopub.status.idle": "2025-11-14T04:18:52.802128Z",
          "shell.execute_reply.started": "2025-11-14T04:18:52.51856Z",
          "shell.execute_reply": "2025-11-14T04:18:52.801555Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#data Augmentation\n",
        "datagen = ImageDataGenerator(rescale= 1./255, validation_split=0.2)\n",
        "\n",
        "train_gen = datagen.flow_from_directory(binary, target_size = (224, 224), batch_size = 32, class_mode = 'categorical', subset='training')\n",
        "\n",
        "validation_gen = datagen.flow_from_directory(binary, target_size = (224, 224), batch_size = 32, class_mode = 'categorical', subset='validation')"
      ],
      "metadata": {
        "id": "uB7R7BnKe0oO",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:52.802742Z",
          "iopub.execute_input": "2025-11-14T04:18:52.802988Z",
          "iopub.status.idle": "2025-11-14T04:18:52.842124Z",
          "shell.execute_reply.started": "2025-11-14T04:18:52.80296Z",
          "shell.execute_reply": "2025-11-14T04:18:52.841608Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet-50 model as the baseline\n",
        "resnet_model = ResNet50(weights = 'imagenet', include_top = False, input_shape = (224, 224, 3))\n",
        "resnet_model.trainable = False\n",
        "x = layers.GlobalAveragePooling2D()(resnet_model.output)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "output = layers.Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs= resnet_model.input, outputs = output)\n",
        "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Gtu8MMO_pW-a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:52.842682Z",
          "iopub.execute_input": "2025-11-14T04:18:52.842923Z",
          "iopub.status.idle": "2025-11-14T04:18:56.690561Z",
          "shell.execute_reply.started": "2025-11-14T04:18:52.842872Z",
          "shell.execute_reply": "2025-11-14T04:18:56.68981Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "  history = model.fit(train_gen, validation_data= validation_gen, batch_size = 32, epochs= 5, verbose= 1)"
      ],
      "metadata": {
        "id": "IjazVzMawOoV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:18:56.691413Z",
          "iopub.execute_input": "2025-11-14T04:18:56.691773Z",
          "iopub.status.idle": "2025-11-14T04:19:57.870619Z",
          "shell.execute_reply.started": "2025-11-14T04:18:56.69175Z",
          "shell.execute_reply": "2025-11-14T04:19:57.870007Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#unfreezig last 20 layers of ResNet-50 model keeping all 'Batchnormalization' layers freezed, finetuning ResNet model\n",
        "model.trainable = True\n",
        "for layer in model.layers[:-20]:\n",
        "  if \"BatchNormalization\" in layer.__class__.__name__:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer = Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "with tf.device(\"/device:GPU:0\"):\n",
        "    history_fine_tuned = model.fit(train_gen, validation_data= validation_gen, batch_size = 32, epochs = 20, verbose= 1)"
      ],
      "metadata": {
        "id": "kn-MRG9ixH9l",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:21:50.397088Z",
          "iopub.execute_input": "2025-11-14T04:21:50.397389Z",
          "iopub.status.idle": "2025-11-14T04:25:01.156308Z",
          "shell.execute_reply.started": "2025-11-14T04:21:50.397368Z",
          "shell.execute_reply": "2025-11-14T04:25:01.155505Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grad-CAM, or Gradient-weighted Class Activation Mapping, is an explainable AI technique that produces a heatmap to show which parts of an image a convolutional neural network (CNN) focuses on to make a specific prediction. It uses the gradients of the classification score to highlight the most important pixels or regions in an image, helping us understand, debug, and improve the model's decision-making process.\n",
        "So now we will be displaying the Grad-CAM for the unfreezed model and take the last layer, which is \"conv5_block3_out\" and see how that layer is predicting.**"
      ],
      "metadata": {
        "id": "lSE80eY5TQUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gradcam for a few images\n",
        "def gradcam(model, img_path, layer_name):\n",
        "    grad_model = tf.keras.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(\"Image path invalid: \" + img_path)\n",
        "\n",
        "    if len(img.shape) == 2 or img.shape[-1] == 1:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        img_array = tf.convert_to_tensor(img, dtype=tf.float32)\n",
        "        conv_outputs, predictions = grad_model([img_array])\n",
        "        class_idx = tf.argmax(predictions[0])\n",
        "        loss = predictions[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis= (0,1,2))\n",
        "\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis= -1)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    heatmap /= tf.reduce_max(heatmap)\n",
        "    heatmap = heatmap.numpy()\n",
        "    return heatmap\n",
        "\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:38:18.911532Z",
          "iopub.execute_input": "2025-11-14T04:38:18.912361Z",
          "iopub.status.idle": "2025-11-14T04:38:18.918975Z",
          "shell.execute_reply.started": "2025-11-14T04:38:18.912321Z",
          "shell.execute_reply": "2025-11-14T04:38:18.918208Z"
        },
        "id": "I9fFsmI5TQUO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#function for displaying Grad-CAM for images\n",
        "def display_grad(img_path, heatmap, alpha= 0.6):\n",
        "    img= cv2.imread(img_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)  # scale 0–1 → 0–255\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    superimposed_img = cv2.addWeighted(img, 1 - alpha, heatmap, alpha, 0)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:38:20.014949Z",
          "iopub.execute_input": "2025-11-14T04:38:20.015491Z",
          "iopub.status.idle": "2025-11-14T04:38:20.020089Z",
          "shell.execute_reply.started": "2025-11-14T04:38:20.015468Z",
          "shell.execute_reply": "2025-11-14T04:38:20.01941Z"
        },
        "id": "ZFk46DYDTQUP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#defining parameters for displaying Grad-CAM\n",
        "img_path = '/kaggle/input/brain-tumor-classification-mri/Testing/glioma_tumor/image(1).jpg'\n",
        "heatmap = gradcam(model, img_path, \"conv5_block3_out\")\n",
        "display_grad(img_path, heatmap)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-14T04:44:44.898669Z",
          "iopub.execute_input": "2025-11-14T04:44:44.899279Z",
          "iopub.status.idle": "2025-11-14T04:44:45.457456Z",
          "shell.execute_reply.started": "2025-11-14T04:44:44.899253Z",
          "shell.execute_reply": "2025-11-14T04:44:45.456701Z"
        },
        "id": "ZQXpsF7JTQUQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The fact that our Grad-CAM is not showing good results and the fact that the accuracy of the model is also low could be due to the issue that the images are not of the same MRI sequence. We can try this Grad-CAM, we need modality consistency.**"
      ],
      "metadata": {
        "id": "hEknIrcCTQUR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "rmlBIgIQTQUS"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}